# -*- coding: utf-8 -*-
"""Untitled44.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uua0MjXuiiLK2pF9uA0GWfLz6Bhvea4G
"""

class NaiveBayesClassifier:
    def __init__(self):
        # Initialize dictionaries to store probabilities
        self.probabilities_class = {}  # P(Play Golf = Yes), P(Play Golf = No)
        self.probabilities_feature = {}  # P(Outlook | Play Golf), P(Temperature | Play Golf), ...

    def fit(self, data, labels):
        # Calculate class probabilities
        total_samples = len(labels)
        unique_classes, class_counts = self.calculate_counts(labels)
        for i, class_label in enumerate(unique_classes):
            # Calculate P(Play Golf = Yes) and P(Play Golf = No)
            self.probabilities_class[class_label] = class_counts[i] / total_samples

        # Calculate feature probabilities
        features = list(data.keys())
        for feature in features:
            # Find unique values for each feature
            unique_values = self.get_unique_values(data[feature])
            self.probabilities_feature[feature] = {}
            for class_label in unique_classes:
                self.probabilities_feature[feature][class_label] = {}
                for value in unique_values:
                    # Calculate P(feature = value | Play Golf)
                    count = self.calculate_feature_count(data[feature], value, labels, class_label)
                    total_count = self.calculate_total_count(labels, class_label)
                    self.probabilities_feature[feature][class_label][value] = count / total_count

    def predict(self, sample):
        # Predict the class for a new sample
        predictions_class = {}
        for class_label, class_prob in self.probabilities_class.items():
            feature_prob_product = 1.0
            for feature, value in sample.items():
                # Multiply the probabilities for each feature value
                feature_prob_product *= self.probabilities_feature[feature][class_label].get(value, 0.0)
            # Store the final probability for each class
            predictions_class[class_label] = class_prob * feature_prob_product

        # Return the class with the highest probability
        return max(predictions_class, key=predictions_class.get)

    def calculate_counts(self, labels):
        # Calculate the count of each class in the dataset
        unique_classes, class_counts = [], []
        for label in labels:
            if label not in unique_classes:
                unique_classes.append(label)
                class_counts.append(1)
            else:
                index = unique_classes.index(label)
                class_counts[index] += 1
        return unique_classes, class_counts

    def calculate_feature_count(self, feature_values, value, labels, class_label):
        # Calculate the count of a specific feature value for a given class
        count = 0
        for i in range(len(labels)):
            if feature_values[i] == value and labels[i] == class_label:
                count += 1
        return count

    def calculate_total_count(self, labels, class_label):
        # Calculate the total count of a specific class in the dataset
        count = 0
        for label in labels:
            if label == class_label:
                count += 1
        return count

    def get_unique_values(self, values):
        # Find unique values for a feature
        unique_values = []
        for value in values:
            if value not in unique_values:
                unique_values.append(value)
        return unique_values

# Example dataset
new_data = {
    'Outlook': ['Rainy', 'Rainy', 'Overcast', 'Sunny', 'Sunny', 'Sunny', 'Overcast', 'Rainy', 'Rainy', 'Sunny', 'Rainy', 'Overcast', 'Overcast', 'Sunny'],
    'Temperature': ['Hot', 'Hot', 'Hot', 'Mild', 'Cool', 'Cool', 'Cool', 'Mild', 'Cool', 'Mild', 'Mild', 'Mild', 'Hot', 'Mild'],
    'Humidity': ['High', 'High', 'High', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'High'],
    'Windy': ['False', 'True', 'False', 'False', 'False', 'True', 'True', 'False', 'False', 'False', 'True', 'True', 'False', 'True'],
    'Play Golf': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No']
}

# Instantiate and train the Naive Bayes classifier
nb_classifier = NaiveBayesClassifier()
nb_classifier.fit(new_data, new_data['Play Golf'])

# Test the classifier with a new sample
new_sample = {'Outlook': 'Rainy', 'Temperature': 'Cool', 'Humidity': 'High', 'Windy': 'True'}
prediction = nb_classifier.predict(new_sample)

# Display new sample and predicted class in tabular form
print("New Sample:")
print(f"{'Feature':<12} {'Value':<12}")
print("----------------------")

# Print feature-value pairs in tabular form
for feature, value in new_sample.items():
    print(f"{feature:<12} {value:<12}")

# Display predicted class
print(f"\nPredicted class: {prediction}")